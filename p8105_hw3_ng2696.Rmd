---
title: "p8105_hw3_ng2696"
author: "Nihan Gencerliler"
date: "10/15/2019"
output: github_document
---
# Homework 3

```{r setup}
library (ggplot2)
library(tidyverse)
library(patchwork)
```

## Problem 1

```{r}
library(p8105.datasets)
data("instacart")
dim(instacart)
head(instacart)
filter(instacart, order_id==1)
```
The "instacart" dataset includes 1384617 observations and 15 variables. Some key variables are product_name, order_id, and user_id. Each observation appears to pertain to a product that was purchased by a user as part of an order that includes other products, as well as information about the order such as time of the order. For instance, there are eight observations where order_id=1, which leads us to conclude that this order included eight products.

How many aisles are there, and which aisles are the most items ordered from?
```{r}
instacart_aisle=
instacart %>%
  group_by(aisle) %>%
  summarize (n=n()) %>%
  arrange(-n) 
  head(instacart_aisle)
```

There are 134 aisles in total and the most items are ordered from the fresh vegetables and fresh fruits aisles, with 	150609 and 150473 items ordered respectively.

Make a plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered. Arrange aisles sensibly, and organize your plot so others can read it.

```{r ,fig.width = 6, fig.height = 4}
instacart_aisle %>%
  filter(n>10000) %>%
  ggplot(aes(x=aisle,y=n)) + geom_point() + theme(axis.text.x= element_text(angle=45))
```

Make a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”. Include the number of times each item is ordered in your table.

```{r}
instacart_popular=
  instacart %>%
  filter(aisle %in% c("baking ingredients","dog food care","packaged vegetables fruits")) %>%
  group_by(product_name,aisle) %>%
  summarize(n=n()) %>%
  group_by(aisle) %>%
  mutate(aisle_ranking=min_rank(desc(n)))
instacart_popular %>%
  group_by(aisle,aisle_ranking,n) %>%
  filter(aisle_ranking<4)%>%
  arrange(aisle,aisle_ranking)

knitr::kable(instacart_popular)
```


Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week; format this table for human readers (i.e. produce a 2 x 7 table).

```{r}
apples_coffee= 
  instacart %>%
  filter(product_name %in% c("Pink Lady Apples","Coffee Ice Cream")) %>%
  group_by(product_name,order_dow) %>%
    summarize(mean_order_hour=mean(order_hour_of_day)) %>%
    pivot_wider(names_from=order_dow,values_from =mean_order_hour)
knitr::kable(apples_coffee)
```

## Problem 2
```{r}
data("brfss_smart2010") 
brfss_smart2010=
janitor::clean_names(brfss_smart2010)
#deciding which observations to include
unique(pull(brfss_smart2010))
brfss_smart2010=
brfss_smart2010 %>%
  filter(topic=="Overall Health",response %in% c("Poor", "Fair", "Excellent", "Good","Very Good")) %>%
  mutate(response_ordered=factor(response, order = TRUE, levels =c("Poor", "Fair", "Good", "Very Good","Excellent")))

```

```{r}
brfss_smart2010 %>%
  group_by(year,locationabbr) %>%
  summarize(n_sites=n_distinct(locationdesc)) %>%
  filter (year %in% c("2002","2010")) %>%
  pivot_wider(names_from=year,values_from=n_sites)
```
In 2002, PA, MA, BJ, CT, FL and NC had at least 7 sites In 2010, FL,NJ, TX, CA, MD, NC, NE, WA, MA, NY, OH, CO, PA, and SC had at least 7 sites.

```{r}
brfss_smart2010 %>%
  filter(response=="Excellent") %>%
  group_by(locationabbr,year) %>%
  summarize(mean_value=mean(data_value)) %>%
  ggplot(aes(x=year,y=mean_value,color=locationabbr))+geom_line()
```
```{r}
density_2006=
brfss_smart2010 %>%
  filter(year =="2006") %>%
  ggplot(aes(x = data_value, fill = response)) + 
  geom_density(alpha = .4, adjust = .5, color = "blue")

density_2010=
brfss_smart2010 %>%
  filter(year =="2010") %>%
  ggplot(aes(x = data_value, fill = response)) + 
  geom_density(alpha = .4, adjust = .5, color = "blue")

density_2006+density_2010

```


## Problem 3

```{r}
#accel_data=
  #read_csv("./p8105_hw3_ng2696_files/accel_data.csv") %>%
  #janitor::clean_names() %>%
  #distinct() 
  #mutate(day="Friday")

#accel_data
```


