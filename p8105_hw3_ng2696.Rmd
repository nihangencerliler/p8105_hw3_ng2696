---
title: "p8105_hw3_ng2696"
author: "Nihan Gencerliler"
date: "10/15/2019"
output: github_document
---
# Homework 3

```{r setup}
library (ggplot2)
library(tidyverse)
library(patchwork)
```

## Problem 1

```{r}
library(p8105.datasets)
data("instacart")
dim(instacart)
head(instacart)
filter(instacart, order_id==1)
```
The "instacart" dataset includes 1384617 observations and 15 variables. Some key variables are product_name, order_id, and user_id. Each observation appears to pertain to a product that was purchased by a user as part of an order that includes other products, as well as information about the order such as time of the order. For instance, there are eight observations where order_id=1, which leads us to conclude that this order included eight products.

How many aisles are there, and which aisles are the most items ordered from?
```{r}
instacart_aisle=
instacart %>%
  group_by(aisle) %>%
  summarize (n=n()) %>%
  arrange(-n) 
  head(instacart_aisle)
```

There are 134 aisles in total and the most items are ordered from the fresh vegetables and fresh fruits aisles, with 	150609 and 150473 items ordered respectively.

Plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered:

```{r ,fig.width = 10, fig.height = 6}
instacart_aisle %>%
  filter(n>10000) %>%
  ggplot(aes(x=aisle,y=n)) + geom_point() + theme(axis.text.x= element_text(angle=45))
```

Table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”:

```{r}
instacart_popular=
  instacart %>%
  filter(aisle %in% c("baking ingredients","dog food care","packaged vegetables fruits")) %>%
  group_by(product_name,aisle) %>%
  summarize(n=n()) %>%
  group_by(aisle) %>%
  mutate(aisle_ranking=min_rank(desc(n)))
instacart_popular %>%
  group_by(aisle,aisle_ranking,n) %>%
  filter(aisle_ranking<4)%>%
  arrange(aisle,aisle_ranking)%>%
knitr::kable()
```


Table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week:

```{r}
apples_coffee= 
  instacart %>%
  filter(product_name %in% c("Pink Lady Apples","Coffee Ice Cream")) %>%
  group_by(product_name,order_dow) %>%
    summarize(mean_order_hour=mean(order_hour_of_day)) %>%
    pivot_wider(names_from=order_dow,values_from =mean_order_hour)
knitr::kable(apples_coffee)
```

## Problem 2

Load and clean data:
```{r}
data("brfss_smart2010") 
brfss_smart2010=
brfss_smart2010 %>%
janitor::clean_names() %>%
  filter(topic=="Overall Health",response %in% c("Poor", "Fair", "Excellent", "Good","Very Good")) %>%
  mutate(response_ordered=factor(response, order = TRUE, levels =c("Poor", "Fair", "Good", "Very Good","Excellent")))

```

```{r}
brfss_smart2010 %>%
  group_by(year,locationabbr) %>%
  summarize(n_sites=n_distinct(locationdesc)) %>%
  filter (year %in% c("2002","2010")) %>%
  pivot_wider(names_from=year,values_from=n_sites)
```
In 2002, PA, MA, BJ, CT, FL and NC had at least 7 sites In 2010, FL,NJ, TX, CA, MD, NC, NE, WA, MA, NY, OH, CO, PA, and SC had at least 7 sites.

Average data_value in each state over time:
```{r}
brfss_smart2010 %>%
  filter(response=="Excellent") %>%
  group_by(locationabbr,year) %>%
  summarize(mean_value=mean(data_value)) %>%
  ggplot(aes(x=year,y=mean_value,color=locationabbr))+geom_line()
```

This plot indicates that, for a given year,  there is a some variation in the mean data
value, with the mean data value in 2006 ranging from around 15 to 27, for instance. There appears to be less variation across time per state, as the lines are somewhat stacked on top of one another.

```{r}

density_2006=
brfss_smart2010 %>%
  filter(year =="2006") %>%
  ggplot(aes(x = data_value, fill = response)) + 
  geom_density(alpha = .4, adjust = .5, color = "blue")

density_2010=
brfss_smart2010 %>%
  filter(year =="2010") %>%
  ggplot(aes(x = data_value, fill = response)) + 
  geom_density(alpha = .4, adjust = .5, color = "blue")

density_2006+density_2010

```

The 2006 and 2010 density plots are very similar to one another. Each response ("excellent", "good" etc.) appears to be clustered around a range of data values with some intersection. For instance, most observations with response=fair have a mean data_value of between 5 and 15.

## Problem 3

Tidied dataset:
```{r}
accel_data=
  read_csv("./p8105_hw3_ng2696_files/accel_data.csv") %>%
  janitor::clean_names() %>%
  distinct() %>%
  pivot_longer(activity_1:activity_1440,
               names_to="minute",
               names_prefix="activity_",
               values_to="activity_count")%>%
  mutate(minute=as.integer(minute)) %>%
  mutate(day_type=ifelse(day %in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday"), "weekday","weekend")) 
dim(accel_data)
head(accel_data)
```
There are 6 variables and 50400 observations in the resulting dataset, with each observation representing a minute within a 5-week span. The variables indicate the week, day, minute, day of the week, whether it's a weekend day or a weekday, and the activity count for that minute.

Total activity across days:
```{r}

  accel_data %>%
  group_by(day_id,day) %>%
  summarize(daily_count=sum(activity_count)) %>%
  knitr::kable()

```

I don't see any particular trends, besides that there are some days where total activity count = 1440, which seems unlikely considering that is the number of minutes per day. It's possible that the accelerometer was not working on these days, which both happen to be Saturdays.

Plot of activity count for each day:
```{r}
accel_data %>%
  ggplot(aes(x=minute,y=activity_count,color=day))+geom_point()
```

Based on this plot, there are some points during the day that have unusually high activity, namely towards the end of the dat around minute 1300, particularly on Friday. Also, it appears that only on Saturdays and Sundays does the person experience a high level of activity in the middle of the day.